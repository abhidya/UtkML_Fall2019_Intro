{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "monetgram.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhidya/UtkML_Fall2019_Intro/blob/master/monetgram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfMpRg_ut8YU",
        "colab_type": "text"
      },
      "source": [
        "# Straightforward PyTorch implementation of CycleGAN\n",
        "\n",
        "This tutorial assumes that you have implemented some basic projects in PyTorch and you know what you're doing. If not, check out this link: https://github.com/jcjohnson/pytorch-examples\n",
        "\n",
        "\n",
        "Have fun implementing this. PM me your results on reddit: u/PhonyPhantom"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv3WeQwTt8YW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import a bunch of stuff\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as Fn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wD0xGkOt8YZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#storing the names of your images and paintings in a list\n",
        "\n",
        "dir = '/content/monet2photo'\n",
        "train_paintings_dir = dir + '/trainA/'\n",
        "train_photos_dir = dir + '/trainB/'\n",
        "\n",
        "paintings_addr = [train_paintings_dir+i for i in os.listdir(train_paintings_dir)]\n",
        "photos_addr = [train_photos_dir+i for i in os.listdir(train_photos_dir)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btNf4HGjt8Yd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocessing data so that every value in the image array is between -1 and 1. \n",
        "\n",
        "def create_train_sets(paintings_addr, photos_addr):\n",
        "    \n",
        "    X_train, Y_train = np.zeros((1072, 3, 128, 128), dtype=np.float32), np.zeros((6287, 3, 128, 128), dtype=np.float32)\n",
        "    \n",
        "    for i in range(len(paintings_addr)):\n",
        "        temp_np = np.asarray(Image.open(paintings_addr[i]).resize((128, 128), Image.ANTIALIAS))  #resizing the image to 128x128\n",
        "        X_train[i] = temp_np.transpose(2, 0, 1)\n",
        "        X_train[i] /= 255\n",
        "        X_train[i] = X_train[i] * 2 -  1\n",
        "        \n",
        "    for i in range(len(photos_addr)):\n",
        "        temp_np = np.asarray(Image.open(photos_addr[i]).resize((128, 128), Image.ANTIALIAS))\n",
        "        Y_train[i] = temp_np.transpose(2, 0, 1)\n",
        "        Y_train[i] /= 255\n",
        "        Y_train[i] = Y_train[i] * 2 -  1\n",
        "    \n",
        "    return X_train, Y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ducaFPOQt8Yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, Y_train = create_train_sets(paintings_addr, photos_addr)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ij1yBkbt8Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving is optional\n",
        "np.save('X_train', X_train)\n",
        "np.save('Y_train', Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDEoLRMXt8Yn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading saved npy files\n",
        "X_train = np.load('X_train.npy')\n",
        "Y_train = np.load('Y_train.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy_A4A5ot8Yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_tensor = torch.from_numpy(X_train)                #Creating Tensors which will later be wrapped into variables\n",
        "Y_tensor = torch.from_numpy(Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-9hBs3nt8Yu",
        "colab_type": "text"
      },
      "source": [
        "Unlike the paper, I use two discriminators per generator as you will see later. This discriminator below is not a part of PatchGAN, it is just a simple discriminator to judge the image as a whole"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_4_85Zit8Yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class discriminator_nonpatch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(discriminator_nonpatch, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=4, stride=2)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=2)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=4, stride=2)\n",
        "        self.bn4 = nn.BatchNorm2d(512)\n",
        "        \n",
        "        self.conv5 = nn.Conv2d(512, 512, kernel_size=6, stride=1)\n",
        "        \n",
        "        self.head = nn.Linear(512, 1)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        x = Fn.leaky_relu(self.conv1(input), negative_slope=0.2)\n",
        "        x = Fn.leaky_relu(self.bn2(self.conv2(x)), negative_slope=0.2)\n",
        "        x = Fn.leaky_relu(self.bn3(self.conv3(x)), negative_slope=0.2)\n",
        "        x = Fn.leaky_relu(self.bn4(self.conv4(x)), negative_slope=0.2)\n",
        "        x = Fn.leaky_relu(self.conv5(x), negative_slope=0.2)\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.head(x)\n",
        "        \n",
        "        return torch.sigmoid(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TewqlFbxt8Yy",
        "colab_type": "text"
      },
      "source": [
        "This one, however, is part of the PatchGAN which takes 70x70 images as input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfbfRcljt8Yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(discriminator, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=4, stride=2)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=2)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=4, stride=2)\n",
        "        self.bn4 = nn.BatchNorm2d(512)\n",
        "        \n",
        "        self.conv5 = nn.Conv2d(512, 512, kernel_size=2, stride=1)\n",
        "        \n",
        "        self.head = nn.Linear(512, 1)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        x = Fn.leaky_relu(self.conv1(input), negative_slope=0.2)\n",
        "        x = Fn.leaky_relu(self.bn2(self.conv2(x)), negative_slope=0.2)\n",
        "        x = Fn.leaky_relu(self.bn3(self.conv3(x)), negative_slope=0.2)\n",
        "        x = Fn.leaky_relu(self.bn4(self.conv4(x)), negative_slope=0.2)\n",
        "        x = Fn.leaky_relu(self.conv5(x), negative_slope=0.2)\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.head(x)\n",
        "        \n",
        "        return torch.sigmoid(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3xbCv3yt8Y4",
        "colab_type": "text"
      },
      "source": [
        "Read the paper's appendix once. This is the model they used for 128x128 images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2Yw_M0vt8Y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class generator(nn.Module):         #padding concerns: reflection? What exactly is the concept behind convTranspose?\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(generator, self).__init__()\n",
        "        \n",
        "        #c7s1-32\n",
        "        self.r1 = nn.ReflectionPad2d(3)\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=7, stride=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        \n",
        "        #d64\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        \n",
        "        #d128\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        #R128\n",
        "        self.r4 = nn.ReflectionPad2d(1)\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.r5 = nn.ReflectionPad2d(1)\n",
        "        self.conv5 = nn.Conv2d(128, 128, kernel_size=3)\n",
        "        self.bn5 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        #R128\n",
        "        self.r6 = nn.ReflectionPad2d(1)\n",
        "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3)\n",
        "        self.bn6 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.r7 = nn.ReflectionPad2d(1)\n",
        "        self.conv7 = nn.Conv2d(128, 128, kernel_size=3)\n",
        "        self.bn7 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        #R128\n",
        "        self.r8 = nn.ReflectionPad2d(1)\n",
        "        self.conv8 = nn.Conv2d(128, 128, kernel_size=3)\n",
        "        self.bn8 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.r9 = nn.ReflectionPad2d(1)\n",
        "        self.conv9 = nn.Conv2d(128, 128, kernel_size=3)\n",
        "        self.bn9 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        #R128\n",
        "        self.r10 = nn.ReflectionPad2d(1)\n",
        "        self.conv10 = nn.Conv2d(128, 128, kernel_size=3)\n",
        "        self.bn10 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.r11 = nn.ReflectionPad2d(1)\n",
        "        self.conv11 = nn.Conv2d(128, 128, kernel_size=3)\n",
        "        self.bn11 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        #R128\n",
        "        self.r12 = nn.ReflectionPad2d(1)\n",
        "        self.conv12 = nn.Conv2d(128, 128, kernel_size=3)\n",
        "        self.bn12 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.r13 = nn.ReflectionPad2d(1)\n",
        "        self.conv13 = nn.Conv2d(128, 128, kernel_size=3)\n",
        "        self.bn13 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        #R128\n",
        "        self.r14 = nn.ReflectionPad2d(1)\n",
        "        self.conv14 = nn.Conv2d(128, 128, kernel_size=3)\n",
        "        self.bn14 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.r15 = nn.ReflectionPad2d(1)\n",
        "        self.conv15 = nn.Conv2d(128, 128, kernel_size=3)\n",
        "        self.bn15 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        #u64\n",
        "        self.uconv16 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
        "        self.bn16 = nn.BatchNorm2d(64)\n",
        "        \n",
        "        #u32\n",
        "        self.uconv17 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
        "        self.bn17 = nn.BatchNorm2d(32)\n",
        "        \n",
        "        #c7s1-3\n",
        "        self.r18 = nn.ReflectionPad2d(3)\n",
        "        self.conv18 = nn.Conv2d(32, 3, kernel_size=7, stride=1)\n",
        "        self.bn18 = nn.BatchNorm2d(3)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        \n",
        "        #c7s1-32\n",
        "        x = Fn.leaky_relu(self.bn1(self.conv1(self.r1(input))), negative_slope=0.2)\n",
        "        \n",
        "        #d64\n",
        "        x = Fn.leaky_relu(self.bn2(self.conv2(x)), negative_slope=0.2)\n",
        "        \n",
        "        #d128\n",
        "        x = Fn.leaky_relu(self.bn3(self.conv3(x)), negative_slope=0.2)\n",
        "        \n",
        "        #R128\n",
        "        x1 = Fn.leaky_relu(self.bn4(self.conv4(self.r4(x))), negative_slope=0.2)\n",
        "        x1 = Fn.leaky_relu(self.bn5(self.conv5(self.r5(x1))), negative_slope=0.2)\n",
        "        \n",
        "        x = x + x1\n",
        "        \n",
        "        #R128\n",
        "        x1 = Fn.leaky_relu(self.bn6(self.conv6(self.r6(x))), negative_slope=0.2)\n",
        "        x1 = Fn.leaky_relu(self.bn7(self.conv7(self.r7(x1))), negative_slope=0.2)\n",
        "        \n",
        "        x = x + x1\n",
        "        \n",
        "        #R128\n",
        "        x1 = Fn.leaky_relu(self.bn8(self.conv8(self.r8(x))), negative_slope=0.2)\n",
        "        x1 = Fn.leaky_relu(self.bn9(self.conv9(self.r9(x1))), negative_slope=0.2)\n",
        "        \n",
        "        x = x + x1\n",
        "        \n",
        "        #R128\n",
        "        x1 = Fn.leaky_relu(self.bn10(self.conv10(self.r10(x))), negative_slope=0.2)\n",
        "        x1 = Fn.leaky_relu(self.bn11(self.conv11(self.r11(x1))), negative_slope=0.2)\n",
        "        \n",
        "        x = x + x1\n",
        "       \n",
        "        #R128\n",
        "        x1 = Fn.leaky_relu(self.bn12(self.conv12(self.r12(x))), negative_slope=0.2)\n",
        "        x1 = Fn.leaky_relu(self.bn13(self.conv13(self.r13(x1))), negative_slope=0.2)\n",
        "        \n",
        "        x = x + x1\n",
        "        \n",
        "        #R128\n",
        "        x1 = Fn.leaky_relu(self.bn14(self.conv14(self.r14(x))), negative_slope=0.2)\n",
        "        x1 = Fn.leaky_relu(self.bn15(self.conv15(self.r15(x1))), negative_slope=0.2)\n",
        "        \n",
        "        x = x + x1\n",
        "        \n",
        "        #u64\n",
        "        x = Fn.leaky_relu(self.bn16(self.uconv16(x)), negative_slope=0.2)\n",
        "        \n",
        "        #u32\n",
        "        x = Fn.leaky_relu(self.bn17(self.uconv17(x)), negative_slope=0.2)\n",
        "        \n",
        "        #c7s1-3\n",
        "        x = Fn.leaky_relu(self.bn18(self.conv18(self.r18(x))), negative_slope=0.2)\n",
        "        \n",
        "        return torch.tanh(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1lUoc0Xt8Y8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWv9EyiKt8ZB",
        "colab_type": "text"
      },
      "source": [
        "The function below is used to divide a 128x128 image into multiple 70x70 images. These images are then passed through our discriminator and then the scores are averaged"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhGW5XAat8ZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pass_through_discriminator(discriminator, image):\n",
        "    score, k = 0, Variable(torch.zeros(1)).type(dtype)\n",
        "    xp, yp = 0, 0\n",
        "    x, y = 70, 70\n",
        "    offset = 25\n",
        "    \n",
        "    while x < 128:\n",
        "        while y < 128:\n",
        "            k += 1\n",
        "            score += discriminator(image[:, :, xp:x, yp:y])\n",
        "            yp += offset\n",
        "            y += offset\n",
        "            \n",
        "        xp += offset\n",
        "        x += offset\n",
        "        \n",
        "    return score / k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWb8KX2at8ZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.FloatTensor\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    dtype = torch.cuda.FloatTensor\n",
        "    \n",
        "G = generator().type(dtype)\n",
        "F = generator().type(dtype)\n",
        "\n",
        "Dg = discriminator().type(dtype)\n",
        "Df = discriminator().type(dtype)\n",
        "Dgnp = discriminator_nonpatch().type(dtype)\n",
        "Dfnp = discriminator_nonpatch().type(dtype)\n",
        "\n",
        "G.apply(weights_init)\n",
        "F.apply(weights_init)\n",
        "Dg.apply(weights_init)\n",
        "Df.apply(weights_init)\n",
        "\n",
        "G_optim = optim.Adam(G.parameters(), lr=0.0002)    #Learning rates directly borrowed from the paper\n",
        "F_optim = optim.Adam(F.parameters(), lr=0.0002)\n",
        "\n",
        "Dg_optim = optim.Adam(Dg.parameters(), lr=0.0001)\n",
        "Df_optim = optim.Adam(Df.parameters(), lr=0.0001)\n",
        "\n",
        "# learning rate decay\n",
        "G_scheduler = optim.lr_scheduler.StepLR(G_optim, step_size=100, gamma=0.1)\n",
        "F_scheduler = optim.lr_scheduler.StepLR(F_optim, step_size=100, gamma=0.1)\n",
        "Dg_scheduler = optim.lr_scheduler.StepLR(Dg_optim, step_size=100, gamma=0.1)\n",
        "Df_scheduler = optim.lr_scheduler.StepLR(Df_optim, step_size=100, gamma=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJMCgVgSt8ZL",
        "colab_type": "text"
      },
      "source": [
        "Sorry about not running the code below for a longer time. I'm still saving money for a decent GPU :(      \n",
        "<br>\n",
        "**But go ahead and give it a go on your machine!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07I67grDt8ZM",
        "colab_type": "code",
        "outputId": "26b46022-41af-458a-c2a1-068d3c64ec35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "epochs = 200\n",
        "batch_size = 1\n",
        "\n",
        "G.train()\n",
        "F.train()\n",
        "Dg.train()\n",
        "Df.train()\n",
        "\n",
        "k = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print( 'Epoch number: {0}'.format(epoch))\n",
        "    \n",
        "    G_scheduler.step()\n",
        "    F_scheduler.step()\n",
        "    Dg_scheduler.step()\n",
        "    Df_scheduler.step()\n",
        "    \n",
        "    for batch in range(X_tensor.size(0) // batch_size):\n",
        "        if batch % 100 == 0:\n",
        "            print('**Batch number: {0}**'.format(batch))\n",
        "        \n",
        "        painting_real = X_tensor[batch * batch_size: (batch + 1) * batch_size]\n",
        "        if k!= 6286:\n",
        "            photo_real = Y_tensor[k % 6287: (k + 1) % 6287]       \n",
        "        else:\n",
        "            photo_real = Y_tensor[6286]\n",
        "            photo_real = photo_real[np.newaxis, ...]\n",
        "        k += 1\n",
        "        \n",
        "        painting_real = Variable(painting_real).type(dtype)\n",
        "        photo_real = Variable(photo_real).type(dtype)\n",
        "        \n",
        "        #Train GAN G\n",
        "        \n",
        "        #Train Dg\n",
        "        photo_fake = G(painting_real)\n",
        "        \n",
        "        scores_real = pass_through_discriminator(Dg, photo_real)\n",
        "        scores_real_np = Dgnp(photo_real)\n",
        "        scores_fake = pass_through_discriminator(Dg, photo_fake)\n",
        "        scores_fake_np = Dgnp(photo_fake)\n",
        "        \n",
        "        label_fake = Variable(torch.zeros(batch_size)).type(dtype)\n",
        "        label_real = Variable(torch.ones(batch_size)).type(dtype)\n",
        "        \n",
        "        scores_real = (0.8 * scores_real + 0.2 * scores_real_np) \n",
        "        scores_fake = (0.8 * scores_fake + 0.2 * scores_fake_np) \n",
        "        \n",
        "        loss1 = torch.mean((scores_real - label_real)**2)\n",
        "        loss2 = torch.mean((scores_fake - label_fake)**2)\n",
        "        \n",
        "        Dg_optim.zero_grad()\n",
        "        \n",
        "        loss_dg = (loss1 + loss2)\n",
        "        if batch % 100 == 0:\n",
        "            print( 'Discriminator G loss: {0}'.format(loss_dg.data) )\n",
        "        loss_dg.backward()\n",
        "        \n",
        "        Dg_optim.step()\n",
        "\n",
        "        #Train G\n",
        "        photo_fake = G(painting_real)\n",
        "        \n",
        "        scores_fake = pass_through_discriminator(Dg, photo_fake)\n",
        "        loss_g = torch.mean((scores_fake - label_real)**2) + 10 * torch.mean(torch.abs(G(F(photo_real)) - photo_real))\n",
        "        if batch % 100 == 0:\n",
        "            print ('Generator G loss: {0}'.format(loss_g.data))\n",
        "        \n",
        "        G_optim.zero_grad()\n",
        "        loss_g.backward()\n",
        "        G_optim.step()\n",
        "        \n",
        "        #Train GAN F\n",
        "        \n",
        "        painting_fake = F(photo_real)\n",
        "        \n",
        "        scores_real = pass_through_discriminator(Df, painting_real)\n",
        "        scores_real_np = Dfnp(painting_real)\n",
        "        scores_fake = pass_through_discriminator(Df, painting_fake)\n",
        "        scores_fake_np = Dfnp(painting_fake)\n",
        "        \n",
        "        scores_real = (0.8 * scores_real + 0.2 * scores_real_np)\n",
        "        scores_fake = (0.8 * scores_fake + 0.2 * scores_fake_np)\n",
        "        \n",
        "        loss1 = torch.mean((scores_real - label_real)**2)\n",
        "        loss2 = torch.mean((scores_fake - label_fake)**2)\n",
        "        \n",
        "        Df_optim.zero_grad()\n",
        "        \n",
        "        loss_df = (loss1 + loss2)\n",
        "        if batch % 100 == 0:\n",
        "            print ('Discriminator F loss: {0}'.format(loss_df.data))\n",
        "        loss_df.backward()\n",
        "        \n",
        "        Df_optim.step()\n",
        "        \n",
        "        #Train F\n",
        "        \n",
        "        painting_fake = F(photo_real)\n",
        "        \n",
        "        scores_fake = pass_through_discriminator(Df, painting_fake)\n",
        "        loss_f = torch.mean((scores_fake - label_real)**2) + 10 * torch.mean(torch.abs(F(G(painting_real)) - painting_real))\n",
        "        if batch % 100 == 0:\n",
        "            print ('Generator F loss: {0}'.format(loss_f.data))\n",
        "        \n",
        "        F_optim.zero_grad()\n",
        "        loss_f.backward()\n",
        "        F_optim.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**Batch number: 800**\n",
            "Discriminator G loss: 0.36610719561576843\n",
            "Generator G loss: 3.2703938484191895\n",
            "Discriminator F loss: 0.26780861616134644\n",
            "Generator F loss: 3.756767988204956\n",
            "**Batch number: 900**\n",
            "Discriminator G loss: 0.11599590629339218\n",
            "Generator G loss: 7.478847503662109\n",
            "Discriminator F loss: 0.23298831284046173\n",
            "Generator F loss: 5.258309364318848\n",
            "**Batch number: 1000**\n",
            "Discriminator G loss: 0.051518987864255905\n",
            "Generator G loss: 4.8462371826171875\n",
            "Discriminator F loss: 0.2615255117416382\n",
            "Generator F loss: 4.084845066070557\n",
            "Epoch number: 2\n",
            "**Batch number: 0**\n",
            "Discriminator G loss: 0.06511892378330231\n",
            "Generator G loss: 6.27385139465332\n",
            "Discriminator F loss: 0.11433573067188263\n",
            "Generator F loss: 5.42141580581665\n",
            "**Batch number: 100**\n",
            "Discriminator G loss: 0.5365719199180603\n",
            "Generator G loss: 5.318724155426025\n",
            "Discriminator F loss: 0.4968474507331848\n",
            "Generator F loss: 3.316683769226074\n",
            "**Batch number: 200**\n",
            "Discriminator G loss: 0.5884717702865601\n",
            "Generator G loss: 3.9527270793914795\n",
            "Discriminator F loss: 0.039625346660614014\n",
            "Generator F loss: 3.8443222045898438\n",
            "**Batch number: 300**\n",
            "Discriminator G loss: 0.05285009741783142\n",
            "Generator G loss: 4.5984578132629395\n",
            "Discriminator F loss: 0.03851844370365143\n",
            "Generator F loss: 6.069432258605957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRXEPdpzt8ZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Simple function for unpreprocessing and displaying results\n",
        "\n",
        "def test_image(img_addr):\n",
        "    img = Image.open(img_addr)\n",
        "    img_np = np.zeros((1, 3, 128, 128), dtype=np.float32)\n",
        "    temp_np = np.asarray(img.resize((128, 128), Image.ANTIALIAS))\n",
        "    plt.imshow(temp_np)\n",
        "    \n",
        "    img_np[0] = temp_np.transpose(2, 0, 1)\n",
        "    \n",
        "    img_np /= 255\n",
        "    img_np = img_np * 2 - 1\n",
        "    img_tensor = torch.from_numpy(img_np)\n",
        "    img_var = Variable(img_tensor).type(dtype)\n",
        "    \n",
        "    photo_var = G(img_var)\n",
        "    photo = photo_var.data.cpu().numpy()\n",
        "    photo = photo[0].transpose(1, 2, 0)\n",
        "    photo = (photo + 1)/2\n",
        "    plt.figure()\n",
        "    plt.imshow(photo)\n",
        "    \n",
        "    paint_var = F(photo_var)\n",
        "    paint = paint_var.data.cpu().numpy()\n",
        "    paint = paint[0].transpose(1, 2, 0)\n",
        "    paint = (paint + 1)/2\n",
        "    plt.figure()\n",
        "    plt.imshow(paint)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE0iNENjt8ZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_image(paintings_addr[27])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "518GSM7Gt8ZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def photo2monet(photo_addr):\n",
        "    img = Image.open(photo_addr)\n",
        "    img_np = np.zeros((1, 3, 128, 128), dtype=np.float32)\n",
        "    temp_np = np.asarray(img.resize((128, 128), Image.ANTIALIAS))\n",
        "    plt.imshow(temp_np)\n",
        "    \n",
        "    img_np[0] = temp_np.transpose(2, 0, 1)\n",
        "    \n",
        "    img_np /= 255\n",
        "    img_np = img_np * 2 - 1\n",
        "    img_tensor = torch.from_numpy(img_np)\n",
        "    img_var = Variable(img_tensor).type(dtype)\n",
        "    \n",
        "    paint_var = F(img_var)\n",
        "    paint = paint_var.data.cpu().numpy()\n",
        "    paint = paint[0].transpose(1, 2, 0)\n",
        "    paint = (paint + 1)/2\n",
        "    plt.figure()\n",
        "    plt.imshow(paint)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtEb8098t8Za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "photo2monet(photos_addr[2900])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}